{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row_ID</th>\n",
       "      <th>Household_ID</th>\n",
       "      <th>Vehicle</th>\n",
       "      <th>Calendar_Year</th>\n",
       "      <th>Model_Year</th>\n",
       "      <th>Blind_Make</th>\n",
       "      <th>Blind_Model</th>\n",
       "      <th>Blind_Submodel</th>\n",
       "      <th>Cat1</th>\n",
       "      <th>Cat2</th>\n",
       "      <th>...</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>NVCat</th>\n",
       "      <th>NVVar1</th>\n",
       "      <th>NVVar2</th>\n",
       "      <th>NVVar3</th>\n",
       "      <th>NVVar4</th>\n",
       "      <th>Claim_Amount</th>\n",
       "      <th>claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>24.0</td>\n",
       "      <td>K</td>\n",
       "      <td>K.78</td>\n",
       "      <td>K.78.2</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261040</td>\n",
       "      <td>0.907793</td>\n",
       "      <td>-0.077998</td>\n",
       "      <td>M</td>\n",
       "      <td>-0.23153</td>\n",
       "      <td>-0.266117</td>\n",
       "      <td>-0.272337</td>\n",
       "      <td>-0.251419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q.22</td>\n",
       "      <td>Q.22.3</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432987</td>\n",
       "      <td>-0.726459</td>\n",
       "      <td>0.204785</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.23153</td>\n",
       "      <td>-0.266117</td>\n",
       "      <td>-0.272337</td>\n",
       "      <td>-0.251419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>17.0</td>\n",
       "      <td>AR</td>\n",
       "      <td>AR.41</td>\n",
       "      <td>AR.41.1</td>\n",
       "      <td>B</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.405797</td>\n",
       "      <td>-0.837048</td>\n",
       "      <td>-1.176858</td>\n",
       "      <td>F</td>\n",
       "      <td>-0.23153</td>\n",
       "      <td>-0.266117</td>\n",
       "      <td>-0.272337</td>\n",
       "      <td>-0.251419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>17.0</td>\n",
       "      <td>AR</td>\n",
       "      <td>AR.41</td>\n",
       "      <td>AR.41.1</td>\n",
       "      <td>B</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.405797</td>\n",
       "      <td>-0.837048</td>\n",
       "      <td>-1.176858</td>\n",
       "      <td>F</td>\n",
       "      <td>-0.23153</td>\n",
       "      <td>-0.266117</td>\n",
       "      <td>-0.272337</td>\n",
       "      <td>-0.251419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>20.0</td>\n",
       "      <td>D</td>\n",
       "      <td>D.20</td>\n",
       "      <td>D.20.0</td>\n",
       "      <td>J</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>2.112691</td>\n",
       "      <td>1.534462</td>\n",
       "      <td>2.347260</td>\n",
       "      <td>F</td>\n",
       "      <td>-0.23153</td>\n",
       "      <td>-0.266117</td>\n",
       "      <td>-0.272337</td>\n",
       "      <td>-0.251419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row_ID  Household_ID  Vehicle  Calendar_Year  Model_Year Blind_Make  \\\n",
       "0       1             1        3           2005        24.0          K   \n",
       "1       2             2        2           2005        22.0          Q   \n",
       "2       3             3        1           2005        17.0         AR   \n",
       "3       4             3        1           2006        17.0         AR   \n",
       "4       5             3        2           2005        20.0          D   \n",
       "\n",
       "  Blind_Model Blind_Submodel Cat1 Cat2  ...       Var6      Var7      Var8  \\\n",
       "0        K.78         K.78.2    D    C  ...   0.261040  0.907793 -0.077998   \n",
       "1        Q.22         Q.22.3    B    C  ...   0.432987 -0.726459  0.204785   \n",
       "2       AR.41        AR.41.1    B    ?  ...  -1.405797 -0.837048 -1.176858   \n",
       "3       AR.41        AR.41.1    B    ?  ...  -1.405797 -0.837048 -1.176858   \n",
       "4        D.20         D.20.0    J    C  ...   2.112691  1.534462  2.347260   \n",
       "\n",
       "  NVCat   NVVar1    NVVar2    NVVar3    NVVar4 Claim_Amount claim  \n",
       "0     M -0.23153 -0.266117 -0.272337 -0.251419          0.0     0  \n",
       "1     O -0.23153 -0.266117 -0.272337 -0.251419          0.0     0  \n",
       "2     F -0.23153 -0.266117 -0.272337 -0.251419          0.0     0  \n",
       "3     F -0.23153 -0.266117 -0.272337 -0.251419          0.0     0  \n",
       "4     F -0.23153 -0.266117 -0.272337 -0.251419          0.0     0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data='/Users/alejandro/AnacondaProjects/Actuary Data/train_set.csv'\n",
    "df = pd.read_csv(data, nrows=100000)\n",
    "\n",
    "# dummy code claims\n",
    "df['claim'] = df.Claim_Amount.apply(lambda x: 0 if x == 0 else 1)\n",
    "df['Model_Year'] = df['Model_Year'] - np.min(df['Model_Year'])\n",
    "df['Model_Year'] = df['Model_Year'].astype('float64')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Cat1', 'Cat2', 'NVCat', 'Var5', 'Var6', 'Var7', 'Var8', 'NVVar1', 'NVVar2', 'NVVar3', 'NVVar4', 'Vehicle', 'Model_Year', 'Blind_Model']]\n",
    "y = df[['claim', 'Claim_Amount']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = y.shape[0]\n",
    "n_classes = 2\n",
    "Y = [int(y[i, 0]) for i in range(len(y[:, 0]))]\n",
    "w1, w2 = n_samples / (n_classes * np.bincount(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(X):\n",
    "    df_cont = pd.DataFrame()\n",
    "    df_cat = pd.DataFrame()\n",
    "    for x in X:\n",
    "        if X[x].dtypes == 'float64':\n",
    "            df_cont['{}'.format(x)] = X[x]\n",
    "        else:\n",
    "            df_cat['{}'.format(x)] = X[x]\n",
    "    \n",
    "    dummy = OneHotEncoder()\n",
    "    dummyC = LabelEncoder()\n",
    "    \n",
    "    df_cat2 = np.zeros((df_cat.shape[0], 1))\n",
    "    for x in df_cat:\n",
    "        y = dummyC.fit_transform(df_cat[x].reshape(-1, 1))\n",
    "        y = dummy.fit_transform(y.reshape(-1, 1)).toarray()\n",
    "        y = pd.DataFrame(y[:, 1:])\n",
    "        df_cat2 = np.hstack((df_cat2, y))\n",
    "    df_cat = pd.DataFrame(df_cat2)\n",
    "    \n",
    "    df = pd.concat([df_cat, pd.DataFrame(df_cont)], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/cv/lib/python3.6/site-packages/ipykernel_launcher.py:15: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/envs/cv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "X = pipeline(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 256\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "myAdam = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=0.00000001, decay=0.0)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_shape=(input_shape,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "\n",
    "model.add(Dense(1024))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "\n",
    "model.add(Dense(1024))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "\n",
    "model.add(Dense(1024))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "\n",
    "model.add(Dense(1024))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "\n",
    "model.add(Dense(1024))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=myAdam,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 85000 samples, validate on 15000 samples\n",
      "Epoch 1/20\n",
      "85000/85000 [==============================] - 74s 872us/step - loss: 1.3492 - acc: 0.4758 - val_loss: 0.6292 - val_acc: 0.9753\n",
      "Epoch 2/20\n",
      "85000/85000 [==============================] - 72s 847us/step - loss: 0.9468 - acc: 0.4456 - val_loss: 0.6690 - val_acc: 0.9945\n",
      "Epoch 3/20\n",
      "85000/85000 [==============================] - 73s 856us/step - loss: 0.8575 - acc: 0.4435 - val_loss: 0.6383 - val_acc: 0.9876\n",
      "Epoch 4/20\n",
      "85000/85000 [==============================] - 72s 848us/step - loss: 0.8033 - acc: 0.4310 - val_loss: 0.6505 - val_acc: 0.9945\n",
      "Epoch 5/20\n",
      "85000/85000 [==============================] - 73s 855us/step - loss: 0.8205 - acc: 0.4657 - val_loss: 0.6314 - val_acc: 0.9771\n",
      "Epoch 6/20\n",
      "85000/85000 [==============================] - 71s 840us/step - loss: 0.7784 - acc: 0.4528 - val_loss: 0.6324 - val_acc: 0.9813\n",
      "Epoch 7/20\n",
      "85000/85000 [==============================] - 71s 839us/step - loss: 0.7878 - acc: 0.4093 - val_loss: 0.6349 - val_acc: 0.9945\n",
      "Epoch 8/20\n",
      "85000/85000 [==============================] - 72s 845us/step - loss: 0.7748 - acc: 0.4440 - val_loss: 0.6353 - val_acc: 0.9945\n",
      "Epoch 9/20\n",
      "85000/85000 [==============================] - 71s 839us/step - loss: 0.8203 - acc: 0.4129 - val_loss: 0.6325 - val_acc: 0.6507\n",
      "Epoch 10/20\n",
      "85000/85000 [==============================] - 71s 840us/step - loss: 0.7683 - acc: 0.4264 - val_loss: 0.6323 - val_acc: 0.9945\n",
      "Epoch 11/20\n",
      "85000/85000 [==============================] - 72s 843us/step - loss: 0.8306 - acc: 0.4204 - val_loss: 0.6337 - val_acc: 0.9945\n",
      "Epoch 12/20\n",
      "85000/85000 [==============================] - 72s 843us/step - loss: 0.7696 - acc: 0.4728 - val_loss: 0.6349 - val_acc: 0.1295\n",
      "Epoch 13/20\n",
      "85000/85000 [==============================] - 71s 840us/step - loss: 0.7873 - acc: 0.4118 - val_loss: 0.6471 - val_acc: 0.1218\n",
      "Epoch 14/20\n",
      "85000/85000 [==============================] - 72s 841us/step - loss: 0.7796 - acc: 0.3888 - val_loss: 0.6358 - val_acc: 0.9805\n",
      "Epoch 15/20\n",
      "85000/85000 [==============================] - 73s 853us/step - loss: 0.7769 - acc: 0.4285 - val_loss: 0.6352 - val_acc: 0.9945\n",
      "Epoch 16/20\n",
      "85000/85000 [==============================] - 71s 841us/step - loss: 0.7473 - acc: 0.4663 - val_loss: 0.6333 - val_acc: 0.1210\n",
      "Epoch 17/20\n",
      "85000/85000 [==============================] - 71s 838us/step - loss: 0.7622 - acc: 0.3971 - val_loss: 0.6346 - val_acc: 0.1319\n",
      "Epoch 18/20\n",
      "85000/85000 [==============================] - 71s 840us/step - loss: 0.7642 - acc: 0.4122 - val_loss: 0.6428 - val_acc: 0.9702\n",
      "Epoch 19/20\n",
      "85000/85000 [==============================] - 74s 872us/step - loss: 0.7724 - acc: 0.4738 - val_loss: 0.6273 - val_acc: 0.9693\n",
      "Epoch 20/20\n",
      "85000/85000 [==============================] - 74s 873us/step - loss: 0.7615 - acc: 0.3936 - val_loss: 0.6334 - val_acc: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2a17dd30>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y[:, 0], \n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size, \n",
    "          validation_split=0.15, \n",
    "          class_weight={0: w1, 1: w2}, \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(y_probs)\n",
    "pred = pred.loc[:,1].apply(lambda x: 1 if x > 0.25 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7704</td>\n",
       "      <td>91677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1\n",
       "0  7704  91677\n",
       "1    23    596"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y[:, 0], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
