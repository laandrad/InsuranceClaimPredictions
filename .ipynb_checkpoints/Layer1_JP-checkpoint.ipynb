{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data='/Users/alejandro/AnacondaProjects/Actuary Data/train_set.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "# test_data = os.getcwd() + r'/Actuary Data/test_set.csv'\n",
    "# df_test = pd.read_csv(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row_ID</th>\n",
       "      <th>Household_ID</th>\n",
       "      <th>Vehicle</th>\n",
       "      <th>Calendar_Year</th>\n",
       "      <th>Model_Year</th>\n",
       "      <th>Blind_Make</th>\n",
       "      <th>Blind_Model</th>\n",
       "      <th>Blind_Submodel</th>\n",
       "      <th>Cat1</th>\n",
       "      <th>Cat2</th>\n",
       "      <th>...</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>NVCat</th>\n",
       "      <th>NVVar1</th>\n",
       "      <th>NVVar2</th>\n",
       "      <th>NVVar3</th>\n",
       "      <th>NVVar4</th>\n",
       "      <th>Claim_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005</td>\n",
       "      <td>K</td>\n",
       "      <td>K.78</td>\n",
       "      <td>K.78.2</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>1.008912</td>\n",
       "      <td>0.261040</td>\n",
       "      <td>0.907793</td>\n",
       "      <td>-0.077998</td>\n",
       "      <td>M</td>\n",
       "      <td>-0.231530</td>\n",
       "      <td>-0.266117</td>\n",
       "      <td>-0.272337</td>\n",
       "      <td>-0.251419</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>2003</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q.22</td>\n",
       "      <td>Q.22.3</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>1.240851</td>\n",
       "      <td>0.432987</td>\n",
       "      <td>-0.726459</td>\n",
       "      <td>0.204785</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.231530</td>\n",
       "      <td>-0.266117</td>\n",
       "      <td>-0.272337</td>\n",
       "      <td>-0.251419</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>1998</td>\n",
       "      <td>AR</td>\n",
       "      <td>AR.41</td>\n",
       "      <td>AR.41.1</td>\n",
       "      <td>B</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.971487</td>\n",
       "      <td>-1.405797</td>\n",
       "      <td>-0.837048</td>\n",
       "      <td>-1.176858</td>\n",
       "      <td>F</td>\n",
       "      <td>-0.231530</td>\n",
       "      <td>-0.266117</td>\n",
       "      <td>-0.272337</td>\n",
       "      <td>-0.251419</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>1998</td>\n",
       "      <td>AR</td>\n",
       "      <td>AR.41</td>\n",
       "      <td>AR.41.1</td>\n",
       "      <td>B</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.971487</td>\n",
       "      <td>-1.405797</td>\n",
       "      <td>-0.837048</td>\n",
       "      <td>-1.176858</td>\n",
       "      <td>F</td>\n",
       "      <td>-0.231530</td>\n",
       "      <td>-0.266117</td>\n",
       "      <td>-0.272337</td>\n",
       "      <td>-0.251419</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>2001</td>\n",
       "      <td>D</td>\n",
       "      <td>D.20</td>\n",
       "      <td>D.20.0</td>\n",
       "      <td>J</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812656</td>\n",
       "      <td>2.112691</td>\n",
       "      <td>1.534462</td>\n",
       "      <td>2.347260</td>\n",
       "      <td>F</td>\n",
       "      <td>-0.231530</td>\n",
       "      <td>-0.266117</td>\n",
       "      <td>-0.272337</td>\n",
       "      <td>-0.251419</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>2001</td>\n",
       "      <td>D</td>\n",
       "      <td>D.20</td>\n",
       "      <td>D.20.0</td>\n",
       "      <td>J</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812656</td>\n",
       "      <td>2.112691</td>\n",
       "      <td>1.534462</td>\n",
       "      <td>2.347260</td>\n",
       "      <td>F</td>\n",
       "      <td>-0.231530</td>\n",
       "      <td>-0.266117</td>\n",
       "      <td>-0.272337</td>\n",
       "      <td>-0.251419</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>2001</td>\n",
       "      <td>AJ</td>\n",
       "      <td>AJ.129</td>\n",
       "      <td>AJ.129.3</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580718</td>\n",
       "      <td>0.551128</td>\n",
       "      <td>0.416289</td>\n",
       "      <td>-0.024395</td>\n",
       "      <td>M</td>\n",
       "      <td>-0.231530</td>\n",
       "      <td>-0.266117</td>\n",
       "      <td>-0.272337</td>\n",
       "      <td>-0.251419</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>2002</td>\n",
       "      <td>AQ</td>\n",
       "      <td>AQ.17</td>\n",
       "      <td>AQ.17.1</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527193</td>\n",
       "      <td>-0.023200</td>\n",
       "      <td>-0.701884</td>\n",
       "      <td>0.226664</td>\n",
       "      <td>M</td>\n",
       "      <td>-0.231530</td>\n",
       "      <td>-0.266117</td>\n",
       "      <td>-0.272337</td>\n",
       "      <td>-0.251419</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>2002</td>\n",
       "      <td>AQ</td>\n",
       "      <td>AQ.17</td>\n",
       "      <td>AQ.17.1</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527193</td>\n",
       "      <td>-0.023200</td>\n",
       "      <td>-0.701884</td>\n",
       "      <td>0.226664</td>\n",
       "      <td>M</td>\n",
       "      <td>-0.231530</td>\n",
       "      <td>-0.266117</td>\n",
       "      <td>-0.272337</td>\n",
       "      <td>-0.251419</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>1995</td>\n",
       "      <td>BW</td>\n",
       "      <td>BW.3</td>\n",
       "      <td>BW.3.0</td>\n",
       "      <td>D</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176312</td>\n",
       "      <td>0.283264</td>\n",
       "      <td>0.969232</td>\n",
       "      <td>-0.792339</td>\n",
       "      <td>N</td>\n",
       "      <td>2.054683</td>\n",
       "      <td>-0.266117</td>\n",
       "      <td>-0.272337</td>\n",
       "      <td>-0.251419</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row_ID  Household_ID  Vehicle  Calendar_Year  Model_Year Blind_Make  \\\n",
       "0       1             1        3           2005        2005          K   \n",
       "1       2             2        2           2005        2003          Q   \n",
       "2       3             3        1           2005        1998         AR   \n",
       "3       4             3        1           2006        1998         AR   \n",
       "4       5             3        2           2005        2001          D   \n",
       "5       6             3        2           2006        2001          D   \n",
       "6       7             4        1           2006        2001         AJ   \n",
       "7       8             4        2           2006        2002         AQ   \n",
       "8       9             4        3           2005        2002         AQ   \n",
       "9      10             5        1           2005        1995         BW   \n",
       "\n",
       "  Blind_Model Blind_Submodel Cat1 Cat2     ...           Var5      Var6  \\\n",
       "0        K.78         K.78.2    D    C     ...       1.008912  0.261040   \n",
       "1        Q.22         Q.22.3    B    C     ...       1.240851  0.432987   \n",
       "2       AR.41        AR.41.1    B    ?     ...      -0.971487 -1.405797   \n",
       "3       AR.41        AR.41.1    B    ?     ...      -0.971487 -1.405797   \n",
       "4        D.20         D.20.0    J    C     ...       0.812656  2.112691   \n",
       "5        D.20         D.20.0    J    C     ...       0.812656  2.112691   \n",
       "6      AJ.129       AJ.129.3    G    C     ...       0.580718  0.551128   \n",
       "7       AQ.17        AQ.17.1    B    C     ...       0.527193 -0.023200   \n",
       "8       AQ.17        AQ.17.1    B    C     ...       0.527193 -0.023200   \n",
       "9        BW.3         BW.3.0    D    ?     ...       0.176312  0.283264   \n",
       "\n",
       "       Var7      Var8 NVCat    NVVar1    NVVar2    NVVar3    NVVar4  \\\n",
       "0  0.907793 -0.077998     M -0.231530 -0.266117 -0.272337 -0.251419   \n",
       "1 -0.726459  0.204785     O -0.231530 -0.266117 -0.272337 -0.251419   \n",
       "2 -0.837048 -1.176858     F -0.231530 -0.266117 -0.272337 -0.251419   \n",
       "3 -0.837048 -1.176858     F -0.231530 -0.266117 -0.272337 -0.251419   \n",
       "4  1.534462  2.347260     F -0.231530 -0.266117 -0.272337 -0.251419   \n",
       "5  1.534462  2.347260     F -0.231530 -0.266117 -0.272337 -0.251419   \n",
       "6  0.416289 -0.024395     M -0.231530 -0.266117 -0.272337 -0.251419   \n",
       "7 -0.701884  0.226664     M -0.231530 -0.266117 -0.272337 -0.251419   \n",
       "8 -0.701884  0.226664     M -0.231530 -0.266117 -0.272337 -0.251419   \n",
       "9  0.969232 -0.792339     N  2.054683 -0.266117 -0.272337 -0.251419   \n",
       "\n",
       "  Claim_Amount  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "5          0.0  \n",
       "6          0.0  \n",
       "7          0.0  \n",
       "8          0.0  \n",
       "9          0.0  \n",
       "\n",
       "[10 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv(data, nrows=100000)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.columns)\n",
    "# print(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy code claims\n",
    "df['claim'] = df.Claim_Amount.apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate feature matrix from labels (claims in {0 = No claim, 1 = Claim})\n",
    "# only continuous variables are included in the model\n",
    "X = df[['Var5', 'Var6', 'Var7', 'Var8', 'NVVar1', 'NVVar2', 'NVVar3', 'NVVar4', 'Vehicle', 'Model_Year', 'Blind_Make', 'Blind_Model', 'Blind_Submodel']]\n",
    "y = df[['claim', 'Claim_Amount']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate feature matrix from labels (claims in {0 = No claim, 1 = Claim})\n",
    "# only continuous variables are included in the model\n",
    "X_train_cont = X_train[['Var5', 'Var6', 'Var7', 'Var8', 'NVVar1', 'NVVar2', 'NVVar3', 'NVVar4']].values\n",
    "y = df[['claim', 'Claim_Amount']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/cv/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n",
      "/anaconda3/envs/cv/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda3/envs/cv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/envs/cv/lib/python3.6/site-packages/ipykernel_launcher.py:15: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/envs/cv/lib/python3.6/site-packages/ipykernel_launcher.py:19: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "X_train_cat = X_train[['Vehicle', 'Model_Year', 'Blind_Make', 'Blind_Model', 'Blind_Submodel']]\n",
    "dummy = OneHotEncoder()\n",
    "\n",
    "vehicle_type = dummy.fit_transform(X_train_cat[X_train_cat.columns[0]].reshape(-1, 1)).toarray()\n",
    "vehicle_type = vehicle_type[:,1:]\n",
    "\n",
    "dummyC = LabelEncoder()\n",
    "\n",
    "Blind_Make = dummyC.fit_transform(X_train_cat[X_train_cat.columns[2]].reshape(-1, 1))\n",
    "Blind_Make = dummy.fit_transform(Blind_Make.reshape(-1, 1)).toarray()\n",
    "Blind_Make = Blind_Make[:,1:]\n",
    "\n",
    "Blind_Model = dummyC.fit_transform(X_train_cat[X_train_cat.columns[3]].reshape(-1, 1))\n",
    "Blind_Model = dummy.fit_transform(Blind_Model.reshape(-1, 1)).toarray()\n",
    "Blind_Model = Blind_Model[:,1:]\n",
    "\n",
    "Blind_Submodel = dummyC.fit_transform(X_train_cat[X_train_cat.columns[4]].reshape(-1, 1))\n",
    "Blind_Submodel = dummy.fit_transform(Blind_Submodel.reshape(-1, 1)).toarray()\n",
    "Blind_Submodel = Blind_Submodel[:,1:]\n",
    "\n",
    "Model_Year = X_train_cat.iloc[:, 1].values.reshape(-1, 1)\n",
    "\n",
    "X_train_cat = np.hstack((vehicle_type, Blind_Make, Blind_Model, Blind_Submodel, Model_Year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9b6c4dadf1d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparsePCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lars'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train_cat_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cat_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cat_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/cv/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/cv/lib/python3.6/site-packages/sklearn/decomposition/sparse_pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    132\u001b[0m                                                \u001b[0mcode_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcode_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                                                \u001b[0mdict_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                                                \u001b[0mreturn_n_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                                                )\n\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/cv/lib/python3.6/site-packages/sklearn/decomposition/dict_learning.py\u001b[0m in \u001b[0;36mdict_learning\u001b[0;34m(X, n_components, alpha, max_iter, tol, method, n_jobs, dict_init, code_init, callback, verbose, random_state, return_n_iter)\u001b[0m\n\u001b[1;32m    533\u001b[0m         dictionary, residuals = _update_dict(dictionary.T, X.T, code.T,\n\u001b[1;32m    534\u001b[0m                                              \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_r2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m                                              random_state=random_state)\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/cv/lib/python3.6/site-packages/sklearn/decomposition/dict_learning.py\u001b[0m in \u001b[0;36m_update_dict\u001b[0;34m(dictionary, Y, code, verbose, return_r2, random_state)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;31m# R <- 1.0 * U_k * V_k^T + R\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;31m# Scale k'th atom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import SparsePCA\n",
    "\n",
    "pca = SparsePCA(n_components=100, method='lars')\n",
    "X_train_cat_pca = pca.fit_transform(X_train_cat)\n",
    "print(X_train_cat_pca.shape)\n",
    "print(X_train_cat_pca.get_covariance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale features to have same variance\n",
    "sc = StandardScaler()\n",
    "X_train_cont = sc.fit_transform(X_train_cont)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit logistic regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train_cont, y_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get in and out of sample accuracy\n",
    "y_pred = model.predict(X_train_cont)\n",
    "in_acc = accuracy_score(y_pred, y_train[:,0])\n",
    "y_pred = model.predict(X_test)\n",
    "out_acc = accuracy_score(y_pred, y_test[:,0])\n",
    "print('In-sample accuracy: {}\\nOut-of-sample accuracy: {}'.format(in_acc, out_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# (1) we now have model of whether someone filed a claim or not\n",
    "# (2) of those who did (claim=1), we need model of y = claim amount\n",
    "\n",
    "Full Model:\n",
    "a) given X, use (1) to assess if claim will be filed\n",
    "b) if for (1), y = 1, then estimate claim amount using (2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_claims = X_train[y_train[:,0] == 1]\n",
    "y_train_claims = y_train[y_train[:,1] != 0, 1]\n",
    "y_train_claims = np.log(1 + y_train_claims)\n",
    "\n",
    "X_test_claims = X_test[y_test[:,0] == 1]\n",
    "y_test_claims = y_test[y_test[:,1] != 0, 1]\n",
    "y_test_claims = np.log(1 + y_test_claims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regr1 = LinearRegression()\n",
    "regr1.fit(X_train_claims, y_train_claims)\n",
    "\n",
    "# scores = cross_val_score(regr, X_claims_train, y_claims_train, cv=5)\n",
    "# print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# print(regr.feature_importances_)\n",
    "\n",
    "#-------------------------#\n",
    "\n",
    "# get in and out of sample accuracy\n",
    "y_pred = regr1.predict(X_train_claims)\n",
    "in_acc = np.sqrt(mean_squared_error(y_pred, y_train_claims))\n",
    "y_pred = regr1.predict(X_test_claims)\n",
    "out_acc = np.sqrt(mean_squared_error(y_pred, y_test_claims))\n",
    "print('In-sample accuracy: {}\\nOut-of-sample accuracy: {}'.format(in_acc, out_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------#\n",
    "# MODEL 1: Random Forest #\n",
    "#------------------------#\n",
    "\n",
    "regr2 = RandomForestRegressor(max_depth=8, random_state=42)\n",
    "regr2.fit(X_train_claims, y_train_claims)\n",
    "\n",
    "# scores = cross_val_score(regr, X_claims_train, y_claims_train, cv=5)\n",
    "# print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "print(regr2.feature_importances_)\n",
    "\n",
    "#-------------------------#\n",
    "\n",
    "# get in and out of sample accuracy\n",
    "y_pred = regr2.predict(X_train_claims)\n",
    "in_acc = np.sqrt(mean_squared_error(y_pred, y_train_claims))\n",
    "y_pred = regr2.predict(X_test_claims)\n",
    "out_acc = np.sqrt(mean_squared_error(y_pred, y_test_claims))\n",
    "print('In-sample accuracy: {}\\nOut-of-sample accuracy: {}'.format(in_acc, out_acc))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "a151beb9-8a80-441f-a3f7-55037187b072",
    "theme": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
